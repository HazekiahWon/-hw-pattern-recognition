{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the problem setup\n",
    "suppose a sample x = (x0,x1,...,xn)  \n",
    "there is m class c0,c1,...,cm  \n",
    "\n",
    "for unknown sample x_k, we compute p(c|x_k), where c=(c0,c1,...,cm)  \n",
    "and c_pred = argmax_c{p(c|x_k}  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the bayes thm.\n",
    "\n",
    "$ p(c_j|x_k)p(x_k) =  p(c_j, x_k) $  \n",
    "\n",
    "$ =  p(x_k|c_j)p(c_j) $  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(x_k)$\n",
    "==============================\n",
    "for $0<=j<=m$, $p(x_k)$ remains the same and thus can be omitted;  \n",
    "\n",
    "$p(c_j)$\n",
    "==============================\n",
    "$p(c_j)$ is the prior and can be computed on the training data;\n",
    "\n",
    "$p(x_k|c_j)$  \n",
    "==============================\n",
    "according to the 'naive' nature,  \n",
    "i.e., attributes are independent on each other\n",
    "    \n",
    " $ p(x_k|c_j) = p(x0_k,x1_k,...,xn_k|c_j)$  \n",
    " \n",
    " $=  p(x0_k|c_j)*p(x1_k|c_j)*...*p(xn_k|c_j)$\n",
    "      \n",
    "\n",
    "for each attributes' conditional proba,\n",
    "1. attributes are discrete values, the proba is calculated as \n",
    "    count of the value divided by total count of all possible values\n",
    "2. attributes are continuous values, obtain a model for the \n",
    "    attribute's distribution estimated as a gaussian.\n",
    "  \n",
    "all of the above computation is done by the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "class NaiveBayes(object):\n",
    "    def __init__(self, continuous_attr, logger='logger.txt'):\n",
    "        logging.basicConfig(filename=logger, filemode='w',\n",
    "                            level=logging.DEBUG, format='%(message)s') # debug < info < warning < error < critical\n",
    "        self.continuous = continuous_attr\n",
    "        self.samples = None\n",
    "        self.labels = None\n",
    "        self.cls = []\n",
    "        self.n_samples = None\n",
    "        self.n_attribute = None\n",
    "        self.n_classes = None\n",
    "        self.class_priors = None\n",
    "        self.c_x_priors = None # n x m, each element is a dict, denoting for each attribute, the distribution of its values\n",
    "\n",
    "\n",
    "    def _read_data(self, file, train=True):\n",
    "        # cls = []\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        with open(file) as f:\n",
    "            for line in f.readlines():\n",
    "                sample = [x.strip().strip('.') for x in line.split(',')]\n",
    "                sample, label = sample[:-1], sample[-1]\n",
    "\n",
    "                if '?' in sample or len(sample)<2:\n",
    "                    continue\n",
    "                # only convert label to numbers during training\n",
    "                if train:\n",
    "                    if label in self.cls:\n",
    "                        label = self.cls.index(label)\n",
    "                    else:\n",
    "                        tmp = label\n",
    "                        label = len(self.cls)\n",
    "                        self.cls.append(tmp)\n",
    "\n",
    "                self.samples.append(sample)\n",
    "                self.labels.append(label)\n",
    "\n",
    "        self.samples = np.array(self.samples)\n",
    "        self.labels = np.array(self.labels)\n",
    "        self.n_classes = len(self.cls)\n",
    "        self.n_samples = len(self.samples)\n",
    "        self.n_attribute = len(self.samples[0])\n",
    "\n",
    "    # def _preprocess_data(self, file, train=True):\n",
    "    #     \"\"\"\n",
    "    #     labels assured to be numbers\n",
    "    #     :return: samples, labels\n",
    "    #     \"\"\"\n",
    "    #     self._read_data(file=file, train=train)\n",
    "\n",
    "\n",
    "    def _compute_class_prior(self):\n",
    "        self.class_priors = np.array([0]*self.n_classes, dtype=np.float32)\n",
    "        for sample,label in zip(self.samples, self.labels):\n",
    "            self.class_priors[label] += 1\n",
    "        self.class_priors /= self.n_samples\n",
    "\n",
    "    def _compute_c_x_prior(self):\n",
    "        tmp = [None]*(self.n_attribute*self.n_classes)\n",
    "        self.c_x_priors = np.reshape(np.array(tmp), newshape=(self.n_classes, self.n_attribute))\n",
    "        # m x n x a\n",
    "        # sample : n x 1 可用花式索引 [label, list(range(n_attribute)), sample]\n",
    "        # self.x_c_priors = np.array([0]*(self.n_classes*self.n_attribute*self.attr_max))\n",
    "        for sample,label in zip(self.samples, self.labels):\n",
    "            for i in range(self.n_attribute):\n",
    "\n",
    "                if not i in self.continuous:\n",
    "                    entry = self.c_x_priors[label, i]\n",
    "                    if entry is None:\n",
    "                        entry = dict()\n",
    "                    if entry.get(sample[i], None) is None:\n",
    "                        entry[sample[i]] = 1\n",
    "                    else:\n",
    "                        entry[sample[i]] += 1\n",
    "                    self.c_x_priors[label, i] = entry\n",
    "        for i in self.continuous:# should make sure it's numerical value\n",
    "            # avg = np.mean(self.samples[,i])\n",
    "            # stddev = np.std(self.samples[:,i])\n",
    "            self.c_x_priors[:,i] = [(np.mean(self.samples[c==self.labels,i].astype(np.int16)),\n",
    "                                     np.std(self.samples[c==self.labels,i].astype(np.int16)))\n",
    "                                    for c in range(len(self.cls))]\n",
    "        # for attributes in self.c_x_priors:\n",
    "        #     # attributes is a vector\n",
    "        #     denoms = [np.sum(list(attr.values())) for attr in attributes] # attr is dict\n",
    "\n",
    "    def _gaussian(self, x, c, i):\n",
    "        yita, sigma = self.c_x_priors[c,i]\n",
    "        fraction = 1. / (np.sqrt(2*np.pi)*sigma)\n",
    "        exp = np.exp(-(x.astype(np.int16)-yita)**2 / (2*sigma**2))\n",
    "        return fraction*exp\n",
    "\n",
    "\n",
    "    def _predict(self, sample):\n",
    "        #p(x_k|c_j)\n",
    "        proba = [1]*self.n_classes\n",
    "\n",
    "        for i,p in enumerate(proba):\n",
    "            # for class i, compute chaining proba for each attr\n",
    "            for idx,attr in enumerate(sample):\n",
    "                if not idx in self.continuous: # discrete values\n",
    "                    entry = self.c_x_priors[i,idx] # dict\n",
    "                    total = self.n_samples*self.class_priors[i]\n",
    "                    if entry.get(attr) is None:\n",
    "                        p *= 1. / (total+len(list(entry.values()))+1)\n",
    "                        # entry[attr] = 1\n",
    "                        # self.c_x_priors[i, idx] = entry\n",
    "                    else:\n",
    "                        p *= np.float32(entry[attr]) / (total)\n",
    "                else:\n",
    "                    p *= self._gaussian(attr, i, idx) # the gaussian density for class i attr idx\n",
    "\n",
    "            proba[i] = p\n",
    "\n",
    "        pred = np.argmax(proba)\n",
    "        pred = self.cls[pred]\n",
    "\n",
    "        return proba, pred\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        self._read_data(file='adult.data')\n",
    "        self._compute_class_prior()\n",
    "        self._compute_c_x_prior()\n",
    "\n",
    "    def test(self):\n",
    "        self._read_data(file='adult.test', train=False)\n",
    "        # the variables are shared with testing\n",
    "        accuracy = 0\n",
    "        for sample,label in zip(self.samples,self.labels):\n",
    "            proba, predicted = self._predict(sample)\n",
    "            if predicted == label:\n",
    "                accuracy += 1\n",
    "                logging.info('sample={} is predict {}'.format(sample, predicted))\n",
    "            else:\n",
    "                logging.warning('=====================================\\n'\n",
    "                                +'sample={} is predict {}\\nwrong answer, should be {}. the estimated proba is {}\\n'.format(sample, predicted, label, proba)\n",
    "                                +'=====================================')\n",
    "\n",
    "\n",
    "        logging.info('the overall accuracy is {}'.format(np.float32(accuracy)/len(self.samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
